package maxdeep.kernels;

import com.maxeler.maxcompiler.v2.kernelcompiler.Kernel;
import com.maxeler.maxcompiler.v2.kernelcompiler.KernelParameters;
import com.maxeler.maxcompiler.v2.kernelcompiler.types.base.DFEVar;
import com.maxeler.maxcompiler.v2.kernelcompiler.types.base.DFEType;
import com.maxeler.maxcompiler.v2.kernelcompiler.stdlib.core.CounterChain;
import com.maxeler.maxcompiler.v2.kernelcompiler.stdlib.memory.Memory;
import com.maxeler.maxcompiler.v2.kernelcompiler.stdlib.core.Mem;
import com.maxeler.maxcompiler.v2.kernelcompiler.types.composite.DFEVector;
import com.maxeler.maxcompiler.v2.kernelcompiler.types.composite.DFEVectorType;
import com.maxeler.maxcompiler.v2.utils.MathUtils;
import com.maxeler.maxcompiler.v2.kernelcompiler.stdlib.core.Stream.OffsetExpr;

/**
 * The fully connected layer for the CNN network
 * @author Ruizhe Zhao <ruizhe.zhao15@imperial.ac.uk>
 */
@Deprecated
public class FCLayerKernel extends Kernel {

  private static final DFEType DATA_TYPE = dfeFloat(8, 24);

  public static final String INP_NAME  = "inp";
  public static final String OUT_NAME  = "opt";
  public static final String WGT_NAME  = "wgt";
  public static final String BIAS_NAME = "bias";

  public FCLayerKernel(KernelParameters params,
    int M,  /* the height of the input matrix */
    int N,  /* the width of the input matrix */
    int P_V /* number of parallelised dot production */
  ) {
    super(params);

    // Vector Type {{{

    DFEVectorType<DFEVar> VEC_TYPE =
      new DFEVectorType<DFEVar>(DATA_TYPE, P_V);
     
    // }}}
    // Auto loop offset {{{

    OffsetExpr loopLength = stream.makeOffsetAutoLoop("fcLoopLength");
    DFEVar L = loopLength.getDFEVar(this, dfeUInt(8));

    // }}}
    // Counters {{{

    CounterChain chain = control.count.makeCounterChain();

    // row index
    DFEVar i = (M == 1) 
      ? constant.var(0)
      : chain.addCounter(M, P_V).cast(dfeInt(32));

    // col index
    DFEVar j = (N == 1)
      ? constant.var(0)
      : chain.addCounter(N, 1).cast(dfeInt(32));

    // loop index 
    DFEVar l = chain.addCounter(L, 1).cast(dfeUInt(8));

    // i.simWatch("i");
    // j.simWatch("j");

    // }}}
    // Streams {{{

    // only read from the input stream while computing the first row
    DFEVar inpEnable = (i === 0) & (l === 0);
    DFEVar inp = io.input(INP_NAME, DATA_TYPE, inpEnable);

    // weight input will always be enabled
    DFEVector<DFEVar> wgt = io.input(WGT_NAME, VEC_TYPE, l === 0);

    // bias
    // read bias when computing the first column for each row
    DFEVar biasEnable = (j === 0) & (l === 0);
    DFEVector<DFEVar> bias = io.input(BIAS_NAME, VEC_TYPE, biasEnable);

    // }}}
    // Input buffer {{{

    Memory<DFEVar> inpBuf = mem.alloc(DATA_TYPE, N);
    DFEVar inpBufWriteAddr = j.cast(dfeUInt(MathUtils.bitsToAddress(N)));
    DFEVar inpVal = inpBuf.port(inpBufWriteAddr, inp, inpEnable,
        Mem.RamWriteMode.WRITE_FIRST);
    // inpVal.simWatch("inpVal");

    // }}}
    // Computation  {{{

    DFEVector<DFEVar> out = VEC_TYPE.newInstance(this);

    // wgt.simWatch("wgt");
    for (int idx = 0; idx < P_V; idx ++) {
      DFEVar val = DATA_TYPE.newInstance(this);
      DFEVar sum = (j === 0) ? bias[idx] : val;
      DFEVar tmp = inpVal * wgt[idx] + sum;
      // tmp.simWatch("tmp_" + Integer.toString(idx));

      out[idx] <== tmp;
      val      <== stream.offset(tmp, -loopLength);
    }

    // }}}
    // Output stream {{{

    DFEVar outEnable = (j === N-1) & (l === L-1);
    io.output(OUT_NAME, out, VEC_TYPE, outEnable);

    // }}}
  }
}
