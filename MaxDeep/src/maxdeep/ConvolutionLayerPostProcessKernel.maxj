package maxdeep;

import com.maxeler.maxcompiler.v2.kernelcompiler.Kernel;
import com.maxeler.maxcompiler.v2.kernelcompiler.KernelParameters;
import com.maxeler.maxcompiler.v2.kernelcompiler.types.base.DFEVar;
import com.maxeler.maxcompiler.v2.kernelcompiler.types.base.DFEType;
import com.maxeler.maxcompiler.v2.kernelcompiler.types.composite.DFEVector;
import com.maxeler.maxcompiler.v2.kernelcompiler.types.composite.DFEVectorType;
import com.maxeler.maxcompiler.v2.kernelcompiler.stdlib.memory.Memory;
import com.maxeler.maxcompiler.v2.kernelcompiler.stdlib.core.CounterChain;
import com.maxeler.maxcompiler.v2.utils.MathUtils;

/**
 * The post processing kernel is aiming at accumulate the result from
 * the previous kernels like MPC, and do some post processing NORM or POOL
 * or ReLU.
 * 
 * NOTE: Currently I think it would be a good idea to implement POOL as a
 * KernelLib or not. Will consider this later.
 * (2017-03-04) Ruizhe Zhao
 */
public class ConvolutionLayerPostProcessKernel extends Kernel {

  public static final String INP_NAME = "POST_PROCESS_INP";
  public static final String OUT_NAME = "POST_PROCESS_OUT";

  public static final String SCALAR_HEIGHT_INP_NAME
    = "CONV_CACHE_SCALAR_HEIGHT_INP";
  public static final String SCALAR_WIDTH_INP_NAME
    = "CONV_CACHE_SCALAR_WIDTH_INP";
  public static final String SCALAR_NUM_CHANNELS_INP_NAME
    = "CONV_CACHE_SCALAR_NUM_CHANNELS_INP";
  public static final String SCALAR_NUM_FILTERS_INP_NAME
    = "CONV_CACHE_SCALAR_NUM_FILTERS_INP";
  public static final String SCALAR_KERNEL_SIZE_INP_NAME
    = "CONV_CACHE_SCALAR_KERNEL_SIZE_INP";

  /**
   * @param params The default kernel parameters made by Manager
   * @param maxHeight Maximum height of the input feature map
   * @param maxWidth Maximum width of the input feature map
   * @param maxNumChannels Maximum number of channels of the input feature map
   * @param maxNumFilters Maximum number of filters of the input feature map
   * @param maxKernelSize Maximum shape of the kernel
   * @param dbg The flag to use DEBUG mode
   */
  public ConvolutionLayerPostProcessKernel(
    KernelParameters params,
    int maxHeight,
    int maxWidth,
    int maxNumChannels,
    int maxNumFilters,
    int maxKernelSize,
    boolean dbg 
  ) {
    super(params);

    // configured by set-and-test
    int latency = 3;

    DFEType type = dfeUInt(32);
    DFEType scalarParamType = dfeUInt(32);

    /**
     * The scalar IO of this kernel is similar to the cache kernel
     * Scalar IOs:
     * - height: The height of the current input feature map
     * - width: The width of the current input feature map
     * - numChannels: The number of channels of the current input feature map
     * - numFilters: The number of filters of the current output feature map
     * - kernelSize: The kernel size of the current computation
     */
    DFEVar height      = io.scalarInput(SCALAR_HEIGHT_INP_NAME, scalarParamType);
    DFEVar width       = io.scalarInput(SCALAR_WIDTH_INP_NAME, scalarParamType);
    DFEVar numChannels = io.scalarInput(SCALAR_NUM_CHANNELS_INP_NAME, scalarParamType);
    DFEVar numFilters  = io.scalarInput(SCALAR_NUM_FILTERS_INP_NAME, scalarParamType);
    DFEVar kernelSize  = io.scalarInput(SCALAR_KERNEL_SIZE_INP_NAME, scalarParamType);

    /**
     * Other constants.
     * - outputHeight: the height of the output feature map
     * - outputWidth: the width of the output feature map
     */
    DFEVar outputHeight = height - kernelSize + 1;
    DFEVar outputWidth = width - kernelSize + 1;

    /**
     * Counters
     *
     */
    CounterChain chain = control.count.makeCounterChain();
    DFEVar c = chain.addCounter(numChannels, 1).cast(dfeInt(32));
    DFEVar f = chain.addCounter(numFilters, 1).cast(dfeInt(32));
    DFEVar h = chain.addCounter(outputHeight, 1).cast(dfeInt(32));
    DFEVar w = chain.addCounter(outputWidth, 1).cast(dfeInt(32));
    DFEVar t = control.count.simpleCounter(32).cast(dfeInt(32));

    /**
     * Output cache:
     * This cache stores the temporary result of each filter. So it's 
     * size is maxHeight * maxWidth * maxNumFilters, which is definitely
     * larger than the space requirement of this cache.
     */
    int cacheSize         = maxHeight * maxWidth * maxNumFilters;
    int cacheAddrBitWidth = MathUtils.bitsToAddress(cacheSize);
    DFEType cacheAddrType = dfeUInt(cacheAddrBitWidth);
    Memory<DFEVar> cache  = mem.alloc(type, cacheSize);

    /**
     * Input value
     */
    DFEVar inp = io.input(INP_NAME, type);

    /**
     * Accumulator
     * This accumulator is quite interesting - It will read the address that
     * belongs to the current cycle, but update the address a few cycles 
     * in the past, which is achieved by using the stream offset.
     * As there is a large gap between the read and update of one address in
     * the output feature map (outputHeight * outputWidth).
     *
     * TODO: Is it possible to decide the latency automatically?
     *
     * TODO: Is it possible to allow multiple update in one cycle without
     * duplicating the BRAM?
     * (2017-03-04) Ruizhe Zhao
     */
    DFEVar cacheAddr = (
      f * (outputWidth * outputHeight).cast(dfeInt(32)) +
      h * outputWidth.cast(dfeInt(32)) +
      w).cast(cacheAddrType);

    DFEVar sum              = (c === 0) ? constant.var(0) : cache.read(cacheAddr);
    DFEVar newSum           = sum + inp;
    DFEVar cacheWriteAddr   = stream.offset(cacheAddr, -latency);
    DFEVar cacheWriteValue  = stream.offset(newSum, -latency);
    DFEVar cacheWriteEnable = t >= latency;

    cache.write(cacheWriteAddr, cacheWriteValue, cacheWriteEnable);

    io.output(OUT_NAME, newSum, type, c === (numChannels - 1).cast(dfeInt(32)));
  }
}
