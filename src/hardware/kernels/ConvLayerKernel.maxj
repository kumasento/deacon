package maxdeep.kernels;

import com.maxeler.maxcompiler.v2.kernelcompiler.Kernel;
import com.maxeler.maxcompiler.v2.kernelcompiler.KernelParameters;
import com.maxeler.maxcompiler.v2.kernelcompiler.types.base.DFEVar;
import com.maxeler.maxcompiler.v2.kernelcompiler.types.base.DFEType;
import com.maxeler.maxcompiler.v2.kernelcompiler.stdlib.core.CounterChain;
import com.maxeler.maxcompiler.v2.kernelcompiler.stdlib.memory.Memory;
import com.maxeler.maxcompiler.v2.kernelcompiler.types.composite.DFEVector;
import com.maxeler.maxcompiler.v2.kernelcompiler.types.composite.DFEVectorType;
import com.maxeler.maxcompiler.v2.utils.MathUtils;

/**
 * The convolution layer for the CNN network
 * @author Ruizhe Zhao <ruizhe.zhao15@imperial.ac.uk>
 */
public class ConvLayerKernel extends Kernel {

  public static final String INP_NAME  = "inp";
  public static final String WGTS_NAME = "wgts";
  public static final String OUT_NAME  = "opt";
  public static final String BIAS_NAME = "bias";

  public static final String CONV_KNL_WGT_NAME = "conv_knl_wgt";
  public static final String CONV_KNL_INP_NAME = "conv_knl_inp";
  public static final String CONV_KNL_OUT_NAME = "conv_knl_opt";

  // if set USE_FMEM_FOR_WGTS, read from wgtsMem, or read from wgtsInpVec
  private Memory<DFEVar> wgtsMem;

  private DFEVector<DFEVar> wgtsInpVec;

  private boolean useFMemForWgts = false;

  /**
   * Create the input component of the ConvLayer
   *
   * @param H height of the input feature map
   * @param W width of the input feature map
   * @param F number of output filters
   * @param C number of input feature map channels
   * @param K kernel size
   * @param P padding size
   * @param S stride size
   * @param P_F parallel in filter
   * @param USE_FMEM_FOR_WGTS flag to set this kernel to use FMem for weights
   */
  public ConvLayerKernel(KernelParameters params,
    int     H,
    int     W,
    int     F,
    int     C,
    int     K,
    int     P,
    int     S,
    int     P_F,
    boolean USE_FMEM_FOR_WGTS,
    DFEType DATA_TYPE
  ) {
    super(params);

    // Constants {{{

    this.useFMemForWgts   = USE_FMEM_FOR_WGTS;
    // input buffer stores a feature map for a single channel
    int KERNEL_UPPER         =   K / 2;
    int KERNEL_LOWER         = - K / 2;
    int INPUT_BUF_SIZE       = H * W;
    int WEIGHT_BUF_SIZE      = C * F * K * K;
    int INPUT_BUF_ADDR_BITS  = MathUtils.bitsToAddress(INPUT_BUF_SIZE);
    int WEIGHT_BUF_ADDR_BITS = MathUtils.bitsToAddress(WEIGHT_BUF_SIZE);

    int WGTS_VECT_SIZE = K * K * P_F;
    DFEVectorType<DFEVar> WGTS_VECT_TYPE =
      new DFEVectorType<DFEVar>(DATA_TYPE, WGTS_VECT_SIZE);

    DFEVectorType<DFEVar> VEC_TYPE = 
      new DFEVectorType<DFEVar>(DATA_TYPE, K * K);

    if (K % 2 == 0)
      KERNEL_UPPER --;

    // }}}
    // Counter {{{
    
    CounterChain chain = control.count.makeCounterChain();
    DFEVar c  = (C == 1)
      ? constant.var(0)
      : chain.addCounter(C, 1).cast(dfeInt(32));
    DFEVar f  = (F == 1)
      ? constant.var(0)
      : chain.addCounter(F, P_F).cast(dfeInt(32));
    DFEVar x  = chain.addCounter(H, S).cast(dfeInt(32));
    DFEVar sx = (S == 1)
      ? constant.var(0) : chain.addCounter(S, 1).cast(dfeInt(32));
    DFEVar y  = chain.addCounter(W, S).cast(dfeInt(32));
    DFEVar sy = (S == 1)
      ? constant.var(0) : chain.addCounter(S, 1).cast(dfeInt(32));
    DFEVar rx = x + sx;
    DFEVar ry = y + sy;

    c.simWatch("c");
    f.simWatch("f");
    rx.simWatch("rx");
    ry.simWatch("ry");

    // }}}
    // Input Stream {{{
    
    DFEVar inpEnable = (f === 0).cast(dfeBool());
    DFEVar inp = io.input(INP_NAME, DATA_TYPE, inpEnable);

    // }}}
    // Weight Buffer {{{
   
    // if (useFMemForWgts) {
    //   wgtsMem = mem.alloc(DATA_TYPE, K * K * C * F);
    //   wgtsMem.mapToCPU(WGTS_NAME);
    // } else {
      wgtsInpVec = io.input(WGTS_NAME, WGTS_VECT_TYPE, rx === 0 & ry === 0);
    //}

    // }}}
    // Input Buffer {{{

    Memory<DFEVar> inputBuf = mem.alloc(DATA_TYPE, INPUT_BUF_SIZE);

    DFEVar writeInpBufAddr = (rx * W + ry);
    writeInpBufAddr = writeInpBufAddr.cast(dfeUInt(INPUT_BUF_ADDR_BITS));
    inputBuf.write(writeInpBufAddr, inp, inpEnable);

    // }}}
    // Generate inp and wgt vectors {{{

    // Input vector {{{
    DFEVector<DFEVar> inpVec = VEC_TYPE.newInstance(this);
    int i = 0;
    for (int dx = KERNEL_LOWER; dx <= KERNEL_UPPER; dx ++) {
      for (int dy = KERNEL_LOWER; dy <= KERNEL_UPPER; dy ++) {
        // conditions
        DFEVar aboveUpper = rx + dx >= H | ry + dy >= W;
        DFEVar belowLower = rx + dx <  0 | ry + dy <  0;
        DFEVar outOfBound = ( aboveUpper | belowLower );
        DFEVar readEnable = inpEnable;

        // address
        // transform 2d coordinates to 1d vector indices
        DFEVar readInpBufAddr  = (rx + dx) * H + (ry + dy);
        readInpBufAddr = readInpBufAddr.cast(dfeUInt(INPUT_BUF_ADDR_BITS));

        // read from stream only when f == 0
        DFEVar curr = (outOfBound)
          ? constant.var(0)
          : ((readEnable) 
              ? stream.offset(inp, dx * W + dy)
              : inputBuf.read(readInpBufAddr));

        // assign
        inpVec[i ++] <== curr;
      }
    }
    // }}}
    // Weight {{{
    for (int idx = 0; idx < P_F; idx ++) {
      DFEVector<DFEVar> wgtsVec = VEC_TYPE.newInstance(this);

      // if (useFMemForWgts) {
      //   for (int k = 0; k < K * K; k ++) {
      //     DFEVar wgtReadAddr = (
      //         (c * (F * K * K)) +
      //         ((f + idx) * (K * K)) +
      //         k).cast(dfeUInt(WEIGHT_BUF_ADDR_BITS));
      //     wgtsVec[k] <== wgtsMem.read(wgtReadAddr);
      //   }
      // } else {
        for (int k = 0; k < K * K; k ++) {
          wgtsVec[k] <== wgtsInpVec[k];
        }
      // }

      String suffix = "_" + Integer.toString(idx);
      io.output(CONV_KNL_INP_NAME + suffix, inpVec, VEC_TYPE);
      io.output(CONV_KNL_WGT_NAME + suffix, wgtsVec, VEC_TYPE);
    }
    // }}}

    // }}}
  }
}
